{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.rendered_html th {max-width: 120px;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "HTML(\"<style>.rendered_html th {max-width: 120px;}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTerminology(file):\n",
    "    \"Reads a terminology file into two dictionaries.\"\n",
    "    cuiName = {}\n",
    "    nameCui = {}\n",
    "    with open(file) as f:\n",
    "        for m in f.readlines():\n",
    "            s = m.split('||')\n",
    "            cui = s[0]\n",
    "            names = s[1].strip().split('|')\n",
    "            cuiName[cui] = names\n",
    "\n",
    "            for name in names:\n",
    "                if name not in nameCui:\n",
    "                    nameCui[name] = []\n",
    "                nameCui[name].append(cui)\n",
    "    return cuiName, nameCui\n",
    "\n",
    "def readAnnotations(path):\n",
    "    \"Reads all .concept files from path into single dataframe.\"\n",
    "    annotations = pd.DataFrame([])\n",
    "    for file in os.listdir(path):\n",
    "        if '.concept' in file:\n",
    "            df = pd.read_table(f'{path}/{file}',sep='\\|\\|',header=None, names=['file_id','ix','type','name','cui'])\n",
    "            df['file'] = [file for x in range(len(df))]\n",
    "            annotations = pd.concat([annotations, df])\n",
    "    annotations = annotations[['cui','name','file']]\n",
    "    return annotations\n",
    "\n",
    "def readCuiType(cuis):\n",
    "    \"Reads in a dictionary mapping cuis to semantic types.\"\n",
    "    \n",
    "    # Load UMLS semantic type mapping file.\n",
    "    try:\n",
    "        mrsty = pd.read_table('umls/mrsty.txt',sep='|',header=0,names=['cui','tui','stn','type','atui','cvf'])[['cui','tui','type']]\n",
    "        mrsty = mrsty[mrsty.cui.isin(cuis)]\n",
    "    except:\n",
    "        raise('NOTE: Must have previously created umls/mrsty.txt by running \"Load UMLS data.ipynb\" to run readCuiType()')\n",
    "    \n",
    "    cuiType = {}\n",
    "    for x in mrsty.iterrows():\n",
    "        if x[1].cui not in cuiType:\n",
    "            cuiType[x[1].cui] = []\n",
    "        cuiType[x[1].cui].append(x[1].type)\n",
    "    return cuiType\n",
    "\n",
    "def getStats(df):\n",
    "    \"Gets stats for given dataframe\"\n",
    "    n = len(df)\n",
    "    tp = sum(df.prediction == df.goldCui)\n",
    "    fp = sum((df.prediction != df.goldCui) & (df.normalized==True))\n",
    "    recall = round(tp/n,2) if n > 0 else 0\n",
    "    precision = round(tp/(tp+fp),2) if (tp+fp) > 0 else 0\n",
    "    return n, tp, fp, recall, precision\n",
    "\n",
    "def sieveResults(results):\n",
    "    \"Returns a sieve-level analysis of results.\"\n",
    "    levels = range(1,max(results.normalizingSieveLevel)+1)\n",
    "    sieves = pd.DataFrame([], columns=['sieve','n','tp','fp', 'sieve_acc', 'agg_recall', 'agg_precision'])\n",
    "    \n",
    "    # Results for each sieve\n",
    "    for i in levels:\n",
    "        df = results[results.normalizingSieveLevel==i]\n",
    "        n, tp, fp, recall, precision = getStats(df)\n",
    "        sieve = df.normalizingSieveName.iloc[0] if n > 0 else \"Unknown\"\n",
    "        sieves.loc[i] = [sieve, n, tp, fp, recall, 0, 0]\n",
    "        sieves.loc[i,'agg_recall'] = round(sum(sieves.tp)/sum(sieves.n),2)\n",
    "        sieves.loc[i,'agg_precision'] = round(sum(sieves.tp)/(sum(sieves.tp)+sum(sieves.fp)),2)\n",
    "    \n",
    "    # Total results\n",
    "    n, tp, fp, recall, precision = getStats(results)\n",
    "    sieves.loc[i+1] = ['Total', n, tp, fp, '-', recall, precision]\n",
    "    return sieves\n",
    "\n",
    "def stratifyByCol(df, col, asc=False):\n",
    "    \"Stratifies the results by given column.\"    \n",
    "    # If the column is a list, explode list into individual rows\n",
    "    if (df.sample(100).applymap(type).mode(0).astype(str) == \"<class 'list'>\")[col][0]:\n",
    "        df = df.explode(col)\n",
    "        \n",
    "    rows = []\n",
    "    for key in set(df[col]):\n",
    "        if not pd.isnull(key):\n",
    "            sub = df[df[col]==key]\n",
    "            rows.append([key] + list(getStats(sub)))\n",
    "    return pd.DataFrame(rows, columns=[col,'n','tp','fp', 'recall', 'precision']).sort_values('precision',ascending=asc)\n",
    "\n",
    "def stratifyByCols(df, cols, asc=False):\n",
    "    for col in cols:\n",
    "        # If the column is a list, explode list into individual rows\n",
    "        if (df.sample(100).applymap(type).mode(0).astype(str) == \"<class 'list'>\")[col][0]:\n",
    "            df = df.explode(col)            \n",
    "    return stratifyByCol(df.assign(combined=df[cols].agg('-'.join, axis=1)), 'combined',asc=asc)\n",
    "\n",
    "def getAmbiguous(df):\n",
    "    \"Find ambiguous names\"\n",
    "    dfMap = {}\n",
    "    for i in range(len(df)):\n",
    "        name = df.iloc[i]['name'].lower().strip()\n",
    "        cui = df.iloc[i]['cui'].lower().strip()\n",
    "\n",
    "        if name not in dfMap:\n",
    "            dfMap[name] = []\n",
    "\n",
    "        dfMap[name] = list(set([cui] + dfMap[name]))\n",
    "\n",
    "    namesToCuis = pd.DataFrame(dfMap.items(),columns=['name','cuis'])\n",
    "    namesToCuis['ambiguous'] = [len(x) > 1 for x in namesToCuis.cuis]\n",
    "    return namesToCuis[namesToCuis.ambiguous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Setup: Load terminology into dictionary, train, test, and results\n",
    "dataset = 'n2c2'\n",
    "cuiName, nameCui = readTerminology(f'../resources/{dataset}_terminology.txt')\n",
    "train = readAnnotations(f'../{dataset}-data/train')\n",
    "# test = readAnnotations(f'../{dataset}-data/test')\n",
    "results = pd.read_csv(f'../{dataset}-data/output/results.txt',sep='\\t')\n",
    "\n",
    "# Load semantic type map\n",
    "cuis = list(set(list(results.goldCui) + list(results.prediction)))\n",
    "cuiType = readCuiType(cuis)\n",
    "\n",
    "# Create analysis dataframe\n",
    "cols = ['normalized','normalizingSource','normalizingSieveName','name','prediction','goldCui','namePermutations']\n",
    "analysis = results[cols]\n",
    "analysis = analysis.assign(goldNames=[['CUI-less'] if c=='CUI-less' else cuiName[c] if c in cuiName else ['Missing'] for c in results.goldCui])\n",
    "analysis = analysis.assign(predTypes=[cuiType[c] if c in cuiType else ['Missing'] for c in results.prediction])\n",
    "analysis = analysis.assign(goldTypes=[cuiType[c] if c in cuiType else ['Missing'] for c in results.goldCui])\n",
    "\n",
    "# Sanity checks\n",
    "# assert len(analysis[analysis.normalized & (analysis.predTypes=='Missing')])==0, 'Predicted CUI missing ST'\n",
    "# assert len(analysis[(analysis.goldCui != 'CUI-less') & analysis.goldTypes=='Missing'])==0, 'Gold CUI missing ST'\n",
    "assert len(analysis[analysis.goldNames=='Missing'])==0, 'Gold names missing'\n",
    "assert len(analysis[analysis.goldTypes=='Missing'])==0, 'Gold types missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = stratifyByCol(analysis, 'predTypes', asc=True)\n",
    "# for p in df[df.precision<.8].predTypes:\n",
    "#     print(f\"'{p}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalizingSieveName</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExactMatchSieve</td>\n",
       "      <td>4202</td>\n",
       "      <td>3973</td>\n",
       "      <td>229</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PrepositionalTransformSieve</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HyphenationSieve</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RemoveStopwordsSieve</td>\n",
       "      <td>276</td>\n",
       "      <td>244</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AmbiguitySieve</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbbreviationExpansionSieve</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmlsEndingSieve</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          normalizingSieveName     n    tp   fp  recall  precision\n",
       "0              ExactMatchSieve  4202  3973  229    0.95       0.95\n",
       "6  PrepositionalTransformSieve    39    36    3    0.92       0.92\n",
       "2             HyphenationSieve    17    15    2    0.88       0.88\n",
       "4         RemoveStopwordsSieve   276   244   32    0.88       0.88\n",
       "5               AmbiguitySieve    36    31    5    0.86       0.86\n",
       "3   AbbreviationExpansionSieve    73    61   12    0.84       0.84\n",
       "1              UmlsEndingSieve    43    32   11    0.74       0.74"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratify performance by column\n",
    "normalized = analysis[analysis.normalized]\n",
    "stratifyByCol(normalized, 'normalizingSource')\n",
    "stratifyByCol(normalized, 'normalizingSieveName')\n",
    "# stratifyByCols(normalized, ['normalizingSource','normalizingSieveName'])\n",
    "# display(stratifyByCols(normalized, ['predTypes','goldTypes']))\n",
    "# stratifyByCol(analysis, 'predTypes', asc=True)\n",
    "# stratifyByCol(analysis, 'goldTypes', asc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col4 {\n",
       "            width:  1000px;\n",
       "        }    #T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col4 {\n",
       "            width:  1000px;\n",
       "        }</style><table id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >name</th>        <th class=\"col_heading level0 col1\" >prediction</th>        <th class=\"col_heading level0 col2\" >goldCui</th>        <th class=\"col_heading level0 col3\" >namePermutations</th>        <th class=\"col_heading level0 col4\" >goldNames</th>        <th class=\"col_heading level0 col5\" >predTypes</th>        <th class=\"col_heading level0 col6\" >goldTypes</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7flevel0_row0\" class=\"row_heading level0 row0\" >3273</th>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col0\" class=\"data row0 col0\" >the heel-shin-test</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col1\" class=\"data row0 col1\" >C0575094</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col2\" class=\"data row0 col2\" >C1288236</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col3\" class=\"data row0 col3\" >the heel-shin-test,heel-shin-test,the heel-shin-test, nos,heel-shin-test, nos,heel-shin-test in the,heel-shin-test with the,heel-shin-test on the,heel-shin-test of the,in heel-shin-test,heel-shin-test in,with heel-shin-test,heel-shin-test with,on heel-shin-test,heel-shin-test on,of heel-shin-test,heel-shin-test of,heel-shin-test, nos in the,nos in the heel-shin-test,,heel-shin-test, nos with the,nos with the heel-shin-test,,heel-shin-test, nos on the,nos on the heel-shin-test,,heel-shin-test, nos of the,nos of the heel-shin-test,,nos in heel-shin-test,,nos with heel-shin-test,,nos on heel-shin-test,,nos of heel-shin-test,,the-heel-shin-test,the heel shin-test,the heel-shin test,heel shin-test,heel-shin test,the-heel-shin-test, nos,the heel-shin-test,-nos,the heel shin-test, nos,the heel-shin test, nos,heel-shin-test,-nos,heel shin-test, nos,heel-shin test, nos,heel-shin-test-in the,heel-shin-test in-the,heel shin-test in the,heel-shin test in the,heel-shin-test-with the,heel-shin-test with-the,heel shin-test with the,heel-shin test with the,heel-shin-test-on the,heel-shin-test on-the,heel shin-test on the,heel-shin test on the,heel-shin-test-of the,heel-shin-test of-the,heel shin-test of the,heel-shin test of the,in-heel-shin-test,in heel shin-test,in heel-shin test,heel-shin-test-in,heel shin-test in,heel-shin test in,with-heel-shin-test,with heel shin-test,with heel-shin test,heel-shin-test-with,heel shin-test with,heel-shin test with,on-heel-shin-test,on heel shin-test,on heel-shin test,heel-shin-test-on,heel shin-test on,heel-shin test on,of-heel-shin-test,of heel shin-test,of heel-shin test,heel-shin-test-of,heel shin-test of,heel-shin test of,heel-shin-test,-nos in the,heel-shin-test, nos-in the,heel-shin-test, nos in-the,heel shin-test, nos in the,heel-shin test, nos in the,nos-in the heel-shin-test,,nos in-the heel-shin-test,,nos in the-heel-shin-test,,nos in the heel shin-test,,nos in the heel-shin test,,heel-shin-test,-nos with the,heel-shin-test, nos-with the,heel-shin-test, nos with-the,heel shin-test, nos with the,heel-shin test, nos with the,nos-with the heel-shin-test,,nos with-the heel-shin-test,,nos with the-heel-shin-test,,nos with the heel shin-test,,nos with the heel-shin test,,heel-shin-test,-nos on the,heel-shin-test, nos-on the,heel-shin-test, nos on-the,heel shin-test, nos on the,heel-shin test, nos on the,nos-on the heel-shin-test,,nos on-the heel-shin-test,,nos on the-heel-shin-test,,nos on the heel shin-test,,nos on the heel-shin test,,heel-shin-test,-nos of the,heel-shin-test, nos-of the,heel-shin-test, nos of-the,heel shin-test, nos of the,heel-shin test, nos of the,nos-of the heel-shin-test,,nos of-the heel-shin-test,,nos of the-heel-shin-test,,nos of the heel shin-test,,nos of the heel-shin test,,nos-in heel-shin-test,,nos in-heel-shin-test,,nos in heel shin-test,,nos in heel-shin test,,nos-with heel-shin-test,,nos with-heel-shin-test,,nos with heel shin-test,,nos with heel-shin test,,nos-on heel-shin-test,,nos on-heel-shin-test,,nos on heel shin-test,,nos on heel-shin test,,nos-of heel-shin-test,,nos of-heel-shin-test,,nos of heel shin-test,,nos of heel-shin test,</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col4\" class=\"data row0 col4\" >['heel-shin test finding', 'heel-shin test finding (finding)']</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col5\" class=\"data row0 col5\" >['Finding']</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow0_col6\" class=\"data row0 col6\" >['Finding']</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7flevel0_row1\" class=\"row_heading level0 row1\" >6156</th>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col0\" class=\"data row1 col0\" >fsh</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col1\" class=\"data row1 col1\" >C0733758</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col2\" class=\"data row1 col2\" >C0202022</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col3\" class=\"data row1 col3\" >fsh,fsh, nos,follicle-stimulating hormone,in fsh,fsh in,with fsh,fsh with,on fsh,fsh on,of fsh,fsh of,nos in fsh,,nos with fsh,,nos on fsh,,nos of fsh,,hormone in follicle-stimulating,hormone with follicle-stimulating,hormone on follicle-stimulating,hormone of follicle-stimulating,follicle-stimulating horm1,horm1 in follicle-stimulating,horm1 with follicle-stimulating,horm1 on follicle-stimulating,horm1 of follicle-stimulating,fsh,-nos,follicle-stimulating-hormone,follicle stimulating hormone,in-fsh,fsh-in,with-fsh,fsh-with,on-fsh,fsh-on,of-fsh,fsh-of,nos-in fsh,,nos in-fsh,,nos-with fsh,,nos with-fsh,,nos-on fsh,,nos on-fsh,,nos-of fsh,,nos of-fsh,,hormone-in follicle-stimulating,hormone in-follicle-stimulating,hormone in follicle stimulating,hormone-with follicle-stimulating,hormone with-follicle-stimulating,hormone with follicle stimulating,hormone-on follicle-stimulating,hormone on-follicle-stimulating,hormone on follicle stimulating,hormone-of follicle-stimulating,hormone of-follicle-stimulating,hormone of follicle stimulating,follicle-stimulating-horm1,follicle stimulating horm1,horm1-in follicle-stimulating,horm1 in-follicle-stimulating,horm1 in follicle stimulating,horm1-with follicle-stimulating,horm1 with-follicle-stimulating,horm1 with follicle stimulating,horm1-on follicle-stimulating,horm1 on-follicle-stimulating,horm1 on follicle stimulating,horm1-of follicle-stimulating,horm1 of-follicle-stimulating,horm1 of follicle stimulating</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col4\" class=\"data row1 col4\" >['follicle stimulating hormone level', 'follicle stimulating hormone measurement', 'follicle stimulating hormone measurement (procedure)', 'fsh measurement']</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col5\" class=\"data row1 col5\" >['Amino Acid, Peptide, or Protein', 'Pharmacologic Substance', 'Hormone']</td>\n",
       "                        <td id=\"T_d7ac62de_3b31_11ec_8004_6c2b59c7ad7frow1_col6\" class=\"data row1 col6\" >['Laboratory Procedure']</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a2f086d9c8>"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove = ['normalized','normalizingSource','normalizingSieveName']#,'goldTypes','predTypes'\n",
    "errors = analysis[(results.prediction != results.goldCui) & (results.normalized==True)]\n",
    "errors = errors[(errors.normalizingSource=='standardTerminology') & (errors.normalizingSieveName=='HyphenationSieve')]\n",
    "errors = errors.loc[:, ~errors.columns.isin(remove)]\n",
    "print(len(errors))\n",
    "errors.style.set_properties(subset=['goldNames'], **{'width': '1000px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sieve</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>sieve_acc</th>\n",
       "      <th>agg_recall</th>\n",
       "      <th>agg_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExactMatchSieve</td>\n",
       "      <td>4271</td>\n",
       "      <td>4026</td>\n",
       "      <td>245</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RemoveStopwordsSieve</td>\n",
       "      <td>282</td>\n",
       "      <td>247</td>\n",
       "      <td>35</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UmlsEndingSieve</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbbreviationExpansionSieve</td>\n",
       "      <td>81</td>\n",
       "      <td>62</td>\n",
       "      <td>19</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PrepositionalTransformSieve</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyphenationSieve</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AmbiguitySieve</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>6619</td>\n",
       "      <td>4477</td>\n",
       "      <td>329</td>\n",
       "      <td>-</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sieve     n    tp   fp sieve_acc agg_recall  \\\n",
       "1               ExactMatchSieve  4271  4026  245      0.94       0.94   \n",
       "2          RemoveStopwordsSieve   282   247   35      0.88       0.94   \n",
       "3               UmlsEndingSieve    75    56   19      0.75       0.94   \n",
       "4    AbbreviationExpansionSieve    81    62   19      0.77       0.93   \n",
       "5   PrepositionalTransformSieve    44    40    4      0.91       0.93   \n",
       "6                       Unknown     0     0    0         0       0.93   \n",
       "7              HyphenationSieve    17    15    2      0.88       0.93   \n",
       "8                       Unknown     0     0    0         0       0.93   \n",
       "9                AmbiguitySieve    36    31    5      0.86       0.93   \n",
       "10                        Total  6619  4477  329         -       0.68   \n",
       "\n",
       "   agg_precision  \n",
       "1           0.94  \n",
       "2           0.94  \n",
       "3           0.94  \n",
       "4           0.93  \n",
       "5           0.93  \n",
       "6           0.93  \n",
       "7           0.93  \n",
       "8           0.93  \n",
       "9           0.93  \n",
       "10          0.93  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = pd.read_csv(f'../{dataset}-data/output/results.txt',sep='\\t')\n",
    "sieveResults(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sieve</th>\n",
       "      <th>n</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>sieve_acc</th>\n",
       "      <th>agg_recall</th>\n",
       "      <th>agg_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExactMatchSieve</td>\n",
       "      <td>4202</td>\n",
       "      <td>3973</td>\n",
       "      <td>229</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RemoveStopwordsSieve</td>\n",
       "      <td>276</td>\n",
       "      <td>244</td>\n",
       "      <td>32</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UmlsEndingSieve</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbbreviationExpansionSieve</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PrepositionalTransformSieve</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HyphenationSieve</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AmbiguitySieve</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>6619</td>\n",
       "      <td>4392</td>\n",
       "      <td>294</td>\n",
       "      <td>-</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sieve     n    tp   fp sieve_acc agg_recall  \\\n",
       "1               ExactMatchSieve  4202  3973  229      0.95       0.95   \n",
       "2          RemoveStopwordsSieve   276   244   32      0.88       0.94   \n",
       "3               UmlsEndingSieve    43    32   11      0.74       0.94   \n",
       "4    AbbreviationExpansionSieve    73    61   12      0.84       0.94   \n",
       "5   PrepositionalTransformSieve    39    36    3      0.92       0.94   \n",
       "6                       Unknown     0     0    0         0       0.94   \n",
       "7              HyphenationSieve    17    15    2      0.88       0.94   \n",
       "8                       Unknown     0     0    0         0       0.94   \n",
       "9                AmbiguitySieve    36    31    5      0.86       0.94   \n",
       "10                        Total  6619  4392  294         -       0.66   \n",
       "\n",
       "   agg_precision  \n",
       "1           0.95  \n",
       "2           0.94  \n",
       "3           0.94  \n",
       "4           0.94  \n",
       "5           0.94  \n",
       "6           0.94  \n",
       "7           0.94  \n",
       "8           0.94  \n",
       "9           0.94  \n",
       "10          0.94  "
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(f'../{dataset}-data/output/results.txt',sep='\\t')\n",
    "sieveResults(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(results.filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getAmbiguous(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omissions = results[results.prediction.isnull() & results.goldNames.notnull()]\n",
    "# omissions[['filename','name','namePermutations','goldCui','goldNames']].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
