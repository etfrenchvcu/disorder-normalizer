{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for loading N2C2 Terminology file\n",
    "## All records must be:\n",
    "- From SNOMED-CT or RxNorm\n",
    "- Have a semantic type used by at least one CUI in the N2C2 training data\n",
    "- Be English language\n",
    "- Be not suppressible (MRCONSO.SUPPRESS!='E')\n",
    "- Have an unambiguous name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRSTY.RRF \n",
    "UMLS semantic type mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MRSTY from source\n",
    "file = 'umls/MRSTY.RRF'\n",
    "cols = ['CUI','TUI','STN','STY','ATUI','CVF','BLANK']\n",
    "mrsty = pd.read_table(file,sep='|',header=None,names=cols)\n",
    "mrsty = mrsty.drop(columns=['BLANK'])\n",
    "mrsty.to_csv('umls/mrsty.txt',sep='|',index=False)\n",
    "# mrsty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRCONSO.RRF \n",
    "UMLS metathesaurus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load MRCONSO from source\n",
    "file = 'umls/MRCONSO.RRF'\n",
    "cols = ['CUI','LAT','TS','LUI','STT','SUI','ISPREF','AUI','SAUI','SCUI','SDUI','SAB','TTY','CODE','STR','SRL','SUPPRESS','CVF','BLANK']\n",
    "mrconso = pd.read_table(file,sep='|',header=None,names=cols)\n",
    "mrconso = mrconso.drop(columns=['BLANK'])\n",
    "umls = mrconso[mrconso.LAT=='ENG']\n",
    "umls = umls[(umls.SAB=='RXNORM') | (umls.SAB=='SNOMEDCT_US')]\n",
    "umls = umls[umls.SUPPRESS!='E'] # Seems like there are obsolete CUIs in the annotations...\n",
    "umls.to_csv('umls/mrconso.txt',sep='|',index=False)\n",
    "# umls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate list of semantic types appearing in training data\n",
    "We will use these to filter UMLS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etfrench\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Load a dataset of all training annotations\n",
    "train_path = '../n2c2-data/all'\n",
    "files = os.listdir(train_path)\n",
    "train = pd.DataFrame([])\n",
    "for file in files:\n",
    "    if '.concept' in file:\n",
    "        df = pd.read_table(f'{train_path}/{file}',sep='\\|\\|',header=None, names=['file_id','ix','type','name','CUI'])\n",
    "        df['file'] = [file for x in range(len(df))]\n",
    "        train = pd.concat([train, df])\n",
    "train = train[['CUI','name','file']]\n",
    "train = pd.merge(train, mrsty, on='CUI')[['CUI','name','file','TUI','STY']]\n",
    "train.to_csv('train.txt',sep='|',index=False)\n",
    "train_cuis = list(set(train.CUI))\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to derive N2C2_TUI\n",
    "# Get distinct TUI list in train order by # of CUIs in UMLS\n",
    "tuis = pd.merge(mrsty, pd.DataFrame(set(train.TUI), columns=['TUI']), on='TUI') \\\n",
    "    .groupby('TUI').count()['CUI'] \\\n",
    "    .reset_index(name='count') \\\n",
    "    .sort_values(['count'], ascending=False) \\\n",
    "    .TUI.tolist()\n",
    "\n",
    "expected = len(set(train.CUI))\n",
    "removed = []\n",
    "\n",
    "for tui in tuis:\n",
    "    # Try removing records with given TUI\n",
    "    subset = train[(train.TUI.isin(tuis)) & (train.TUI != tui)]\n",
    "    \n",
    "    # If removing the TUI didn't drop unique CUIs, remove it permanently\n",
    "    if expected == len(set(subset.CUI)):\n",
    "        tuis.remove(tui)\n",
    "        \n",
    "n2c2_tui = train[(train.TUI.isin(tuis))] \\\n",
    "    .groupby('TUI').count()['CUI'] \\\n",
    "    .reset_index(name='count') \\\n",
    "    .sort_values(['count'], ascending=False)\n",
    "\n",
    "with open('../scripts/n2c2_tui.txt','w+') as f:\n",
    "    for tui in list(n2c2_tui.TUI):\n",
    "        f.write(f'{tui}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate abbreviations.txt\n",
    "Filter UMLS data to pick out abbreviations. We'll remove abbreviation records and any record that matches an abbreviation from the terminology file we generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8159  unique acronyms\n"
     ]
    }
   ],
   "source": [
    "# Find records with names of the form 'BW - Birth weight' and exclude records with parens.\n",
    "acronyms = umls[[bool(re.search(r'^[A-z0-9]{2,} - .+ .+[^)]$',s)) if pd.notnull(s) else False for s in umls.STR]]\n",
    "\n",
    "# Acronym contains at least one letter.\n",
    "acronyms = acronyms[[bool(re.search(r'^.*[A-z]+.* - .+ .+',s)) for s in acronyms.STR]]\n",
    "\n",
    "# Filter out records starting with full words 'adolescent - needs help'.\n",
    "acronyms = acronyms[[not bool(re.search(r'^[A-z0-9]+[a-z]{3,} - .+ .+',s)) for s in acronyms.STR]]\n",
    "print(len(set(acronyms.STR)), ' unique acronyms')\n",
    "\n",
    "# Write acronyms file\n",
    "abbreviations = []\n",
    "with open('../resources/abbreviations.txt', 'w+') as f:\n",
    "    for s in sorted(set(list(acronyms.STR))):\n",
    "        parts = s.split('-')\n",
    "        abbreviation = parts[0].strip().lower()\n",
    "        expansion = parts[1].strip().lower()\n",
    "        f.write(f'{abbreviation}||{expansion}\\n')\n",
    "        \n",
    "        abbreviations.append(abbreviation)\n",
    "abbreviations = set(abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate n2c2_terminology.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CUIs: 548694\n",
      "Unique names: 1606676\n"
     ]
    }
   ],
   "source": [
    "# Drop acronym records and any record with a string matching an acronym\n",
    "umls_term = umls.drop(acronyms.index, axis=0)\n",
    "umls_term = umls_term[umls_term.STR.notnull()]\n",
    "umls_term.STR = [x.lower().strip() for x in umls_term.STR]\n",
    "umls_term = umls_term[~umls_term.STR.isin(abbreviations)]\n",
    "\n",
    "# Filter by TUIs in N2C2 train\n",
    "umls_term = umls_term[['CUI','STR']]\n",
    "umls_term = pd.merge(umls_term, mrsty[['CUI','TUI']], on='CUI')\n",
    "umls_term = pd.merge(umls_term, n2c2_tui[['TUI']], on='TUI')\n",
    "umls_term = umls_term[['CUI','STR']]\n",
    "\n",
    "# Add \"angina disorder\" for names like \"angina (disorder)\"\n",
    "disorder_paren = umls_term[umls_term.STR.str.contains(r'\\(disorder\\)')].reset_index(drop=True)\n",
    "disorder_paren.STR = [x.replace('(disorder)',' disorder ') for x in disorder_paren.STR]\n",
    "umls_term = pd.concat([umls_term,disorder_paren],ignore_index=True)\n",
    "\n",
    "# Add \"sedation\" for names like \"[d]sedation\"\n",
    "letter_bracket = umls_term[umls_term.STR.str.contains(r'\\[[a-z]\\]')].reset_index(drop=True)\n",
    "letter_bracket.STR = [re.sub(r'\\[[a-z]\\]','',x).strip() for x in letter_bracket.STR]\n",
    "umls_term = pd.concat([umls_term,letter_bracket],ignore_index=True)\n",
    "\n",
    "# THIS IS CREATING AMBIGUITY IT SHOULDN'T. Just remove records with parens?\n",
    "# # Remove parentheticals like \"Electroretinograph (physical object)\"\n",
    "# umls_term.STR = [re.sub(r'\\(.*\\)',' ',x) for x in umls_term.STR]\n",
    "\n",
    "# Remove extra whitespace\n",
    "umls_term.STR = [re.sub(r'\\s+',' ',x) for x in umls_term.STR]\n",
    "umls_term.STR = [x.lower().strip() for x in umls_term.STR]\n",
    "umls_term = umls_term.drop_duplicates()\n",
    "umls_term = umls_term[umls_term.STR!='']\n",
    "\n",
    "# Remove CUIs with ambiguous names\n",
    "ambiguous = [item for item, count in collections.Counter(list(umls_term.STR)).items() if count > 1]\n",
    "umls_term = umls_term[~umls_term.STR.isin(ambiguous)]\n",
    "\n",
    "print('Unique CUIs:', len(set(umls_term.CUI)))\n",
    "print('Unique names:', len(set(umls_term.STR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C0428654||carbon dioxide concentration - respired|respired carbon dioxide (co₂) concentration|respired carbon dioxide concentration|respired carbon dioxide concentration (observable entity)\n",
      "C2584948||lipoprotein associated phospholipase a₂ measurement|lipoprotein associated phospholipase a₂ measurement (procedure)\n",
      "C2585014||partial pressure arterial oxygen/fraction inspired oxygen ratio|ratio of arterial oxygen tension to inspired oxygen fraction|ratio of arterial oxygen tension to inspired oxygen fraction (pao₂/fio₂)|ratio of arterial oxygen tension to inspired oxygen fraction (procedure)\n",
      "C2585389||thromboelastography (teg) alpha angle|thromboelastography (teg) α angle|thromboelastography alpha angle|thromboelastography alpha angle (observable entity)\n",
      "C4316637||galad score|gender, age, afp-l3, α fetoprotein and des-carboxy-prothrombin score|gender, age, afp-l3, α fetoprotein and des-carboxy-prothrombin score (assessment scale)\n"
     ]
    }
   ],
   "source": [
    "# Write n2c2_terminology.txt\n",
    "n2c2_terminology = umls_term.groupby('CUI')['STR'].apply(list)\n",
    "n2c2_terminology = pd.DataFrame(n2c2_terminology).reset_index()\n",
    "n2c2_terminology['NAMES'] = ['|'.join(sorted(x)) for x in n2c2_terminology.STR]\n",
    "\n",
    "with open('../resources/n2c2_terminology.txt', 'w+') as f:\n",
    "    for x in n2c2_terminology.iterrows():\n",
    "        try:\n",
    "            f.write(f'{x[1].CUI}||{x[1].NAMES}\\n')\n",
    "        except:\n",
    "            print(f'{x[1].CUI}||{x[1].NAMES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
